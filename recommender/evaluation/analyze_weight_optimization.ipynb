{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weight Optimization Analysis\n",
    "\n",
    "This notebook analyzes the weight optimization results for the EU Legal Recommender system, focusing on understanding the impact of different weight configurations on recommendation quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set plot styling\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette('viridis')\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Optimization Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Load the optimization results\n",
    "with open('energy_optimization_results.json', 'r') as f:\n",
    "    results = json.load(f)\n",
    "\n",
    "# Check which clients are in the results\n",
    "clients = list(results.keys())\n",
    "print(f\"Clients in results: {clients}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract and Process Data\n",
    "\n",
    "Let's extract the key information for each configuration and organize it into DataFrames for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def extract_similarity_results(client_results):\n",
    "    \"\"\"Extract similarity weight optimization results for precision and NDCG.\"\"\"\n",
    "    similarity_results = []\n",
    "    \n",
    "    if 'full_profile' in client_results and 'similarity' in client_results['full_profile']:\n",
    "        similarity = client_results['full_profile']['similarity']\n",
    "        \n",
    "        # Process precision results\n",
    "        if 'precision@10' in similarity:\n",
    "            precision_data = similarity['precision@10']\n",
    "            for result in precision_data.get('all_results', []):\n",
    "                if 'weights' in result and 'score' in result:\n",
    "                    row = {\n",
    "                        'text_weight': result['weights'].get('text_weight', 0),\n",
    "                        'categorical_weight': result['weights'].get('categorical_weight', 0),\n",
    "                        'precision@10': result.get('score', 0),\n",
    "                        'metric': 'precision@10'\n",
    "                    }\n",
    "                    similarity_results.append(row)\n",
    "        \n",
    "        # Process NDCG results\n",
    "        if 'ndcg@10' in similarity:\n",
    "            ndcg_data = similarity['ndcg@10']\n",
    "            for result in ndcg_data.get('all_results', []):\n",
    "                if 'weights' in result and 'score' in result:\n",
    "                    row = {\n",
    "                        'text_weight': result['weights'].get('text_weight', 0),\n",
    "                        'categorical_weight': result['weights'].get('categorical_weight', 0),\n",
    "                        'ndcg@10': result.get('score', 0),\n",
    "                        'metric': 'ndcg@10'\n",
    "                    }\n",
    "                    similarity_results.append(row)\n",
    "    \n",
    "    return pd.DataFrame(similarity_results) if similarity_results else None\n",
    "\n",
    "def extract_personalization_results(client_results):\n",
    "    \"\"\"Extract personalization weight optimization results for different configurations.\"\"\"\n",
    "    personalization_results = []\n",
    "    \n",
    "    for config in ['full_profile', 'expert_only', 'categorical_only', 'historical_only']:\n",
    "        if config in client_results and 'personalization' in client_results[config]:\n",
    "            personalization = client_results[config]['personalization']\n",
    "            \n",
    "            # Process precision results\n",
    "            if 'precision@10' in personalization:\n",
    "                precision_data = personalization['precision@10']\n",
    "                for result in precision_data.get('all_results', []):\n",
    "                    if 'weights' in result:\n",
    "                        row = {\n",
    "                            'expert_weight': result['weights'].get('expert_weight', 0),\n",
    "                            'historical_weight': result['weights'].get('historical_weight', 0),\n",
    "                            'categorical_weight': result['weights'].get('categorical_weight', 0),\n",
    "                            'precision@10': result.get('score', 0),\n",
    "                            'config': config,\n",
    "                            'metric': 'precision@10'\n",
    "                        }\n",
    "                        personalization_results.append(row)\n",
    "            \n",
    "            # Process NDCG results\n",
    "            if 'ndcg@10' in personalization:\n",
    "                ndcg_data = personalization['ndcg@10']\n",
    "                for result in ndcg_data.get('all_results', []):\n",
    "                    if 'weights' in result:\n",
    "                        row = {\n",
    "                            'expert_weight': result['weights'].get('expert_weight', 0),\n",
    "                            'historical_weight': result['weights'].get('historical_weight', 0),\n",
    "                            'categorical_weight': result['weights'].get('categorical_weight', 0),\n",
    "                            'ndcg@10': result.get('score', 0),\n",
    "                            'config': config,\n",
    "                            'metric': 'ndcg@10'\n",
    "                        }\n",
    "                        personalization_results.append(row)\n",
    "    \n",
    "    return pd.DataFrame(personalization_results) if personalization_results else None\n",
    "\n",
    "def extract_embedding_results(client_results):\n",
    "    \"\"\"Extract embedding weight optimization results.\"\"\"\n",
    "    embedding_results = []\n",
    "    \n",
    "    if 'full_profile' in client_results and 'embedding' in client_results['full_profile']:\n",
    "        embedding = client_results['full_profile']['embedding']\n",
    "        \n",
    "        # Process precision results\n",
    "        if 'precision@10' in embedding:\n",
    "            precision_data = embedding['precision@10']\n",
    "            for result in precision_data.get('all_results', []):\n",
    "                if 'weights' in result and 'score' in result:\n",
    "                    row = {\n",
    "                        'summary_weight': result['weights'].get('summary_weight', 0),\n",
    "                        'keyword_weight': result['weights'].get('keyword_weight', 0),\n",
    "                        'precision@10': result.get('score', 0),\n",
    "                        'metric': 'precision@10'\n",
    "                    }\n",
    "                    embedding_results.append(row)\n",
    "        \n",
    "        # Process NDCG results\n",
    "        if 'ndcg@10' in embedding:\n",
    "            ndcg_data = embedding['ndcg@10']\n",
    "            for result in ndcg_data.get('all_results', []):\n",
    "                if 'weights' in result and 'score' in result:\n",
    "                    row = {\n",
    "                        'summary_weight': result['weights'].get('summary_weight', 0),\n",
    "                        'keyword_weight': result['weights'].get('keyword_weight', 0),\n",
    "                        'ndcg@10': result.get('score', 0),\n",
    "                        'metric': 'ndcg@10'\n",
    "                    }\n",
    "                    embedding_results.append(row)\n",
    "    \n",
    "    return pd.DataFrame(embedding_results) if embedding_results else None\n",
    "\n",
    "# Extract data for the renewable energy client\n",
    "client = 'renewable_energy_client'\n",
    "similarity_df = extract_similarity_results(results[client])\n",
    "personalization_df = extract_personalization_results(results[client])\n",
    "embedding_df = extract_embedding_results(results[client])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze Similarity Weight Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "if similarity_df is not None:\n",
    "    # Display statistics for similarity weights\n",
    "    print(\"Summary statistics for similarity weights:\")\n",
    "    print(similarity_df.describe())\n",
    "    \n",
    "    # Find the best weights for precision\n",
    "    precision_df = similarity_df[similarity_df['metric'] == 'precision@10']\n",
    "    best_precision = precision_df.sort_values('precision@10', ascending=False).head(5)\n",
    "    print(\"\\nTop 5 weights for precision@10:\")\n",
    "    print(best_precision)\n",
    "    \n",
    "    # Find the best weights for NDCG\n",
    "    ndcg_df = similarity_df[similarity_df['metric'] == 'ndcg@10']\n",
    "    if not ndcg_df.empty:\n",
    "        best_ndcg = ndcg_df.sort_values('ndcg@10', ascending=False).head(5)\n",
    "        print(\"\\nTop 5 weights for ndcg@10:\")\n",
    "        print(best_ndcg)\n",
    "    \n",
    "    # Create a plot of text_weight vs performance\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    \n",
    "    # Plot precision results\n",
    "    if not precision_df.empty:\n",
    "        plt.scatter(precision_df['text_weight'], precision_df['precision@10'], \n",
    "                   label='Precision@10', alpha=0.7)\n",
    "    \n",
    "    # Plot NDCG results if available\n",
    "    if not ndcg_df.empty:\n",
    "        plt.scatter(ndcg_df['text_weight'], ndcg_df['ndcg@10'], \n",
    "                   label='NDCG@10', alpha=0.7)\n",
    "    \n",
    "    plt.xlabel('Text Weight')\n",
    "    plt.ylabel('Performance Score')\n",
    "    plt.title('Performance vs. Text Weight')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No similarity weight data available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze Personalization Weight Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "if personalization_df is not None:\n",
    "    # Number of non-zero results for precision and NDCG\n",
    "    print(\"Number of non-zero precision results:\")\n",
    "    precision_counts = personalization_df[personalization_df['metric'] == 'precision@10'].query('`precision@10` > 0').groupby('config').size()\n",
    "    print(precision_counts)\n",
    "    \n",
    "    print(\"\\nNumber of non-zero NDCG results:\")\n",
    "    ndcg_counts = personalization_df[personalization_df['metric'] == 'ndcg@10'].query('`ndcg@10` > 0').groupby('config').size()\n",
    "    print(ndcg_counts)\n",
    "    \n",
    "    # Best configurations for each metric\n",
    "    print(\"\\nBest configurations for precision@10:\")\n",
    "    best_precision = personalization_df[personalization_df['metric'] == 'precision@10'].sort_values('precision@10', ascending=False).head(5)\n",
    "    print(best_precision[['config', 'expert_weight', 'historical_weight', 'categorical_weight', 'precision@10']])\n",
    "    \n",
    "    print(\"\\nBest configurations for NDCG@10:\")\n",
    "    best_ndcg = personalization_df[personalization_df['metric'] == 'ndcg@10'].sort_values('ndcg@10', ascending=False).head(5)\n",
    "    print(best_ndcg[['config', 'expert_weight', 'historical_weight', 'categorical_weight', 'ndcg@10']])\n",
    "    \n",
    "    # Create a 3D scatter plot for full profile results\n",
    "    full_profile = personalization_df[personalization_df['config'] == 'full_profile']\n",
    "    if not full_profile.empty:\n",
    "        precision_3d = full_profile[full_profile['metric'] == 'precision@10']\n",
    "        \n",
    "        if not precision_3d.empty:\n",
    "            from mpl_toolkits.mplot3d import Axes3D\n",
    "            \n",
    "            fig = plt.figure(figsize=(12, 10))\n",
    "            ax = fig.add_subplot(111, projection='3d')\n",
    "            \n",
    "            scatter = ax.scatter(precision_3d['expert_weight'], \n",
    "                               precision_3d['historical_weight'], \n",
    "                               precision_3d['categorical_weight'],\n",
    "                               c=precision_3d['precision@10'],\n",
    "                               cmap='viridis',\n",
    "                               s=50,\n",
    "                               alpha=0.7)\n",
    "            \n",
    "            ax.set_xlabel('Expert Weight')\n",
    "            ax.set_ylabel('Historical Weight')\n",
    "            ax.set_zlabel('Categorical Weight')\n",
    "            ax.set_title('Personalization Weights vs. Precision@10')\n",
    "            \n",
    "            # Add color bar\n",
    "            cbar = fig.colorbar(scatter, ax=ax, shrink=0.7)\n",
    "            cbar.set_label('Precision@10')\n",
    "            \n",
    "            plt.show()\n",
    "    \n",
    "    # Compare performance across configurations\n",
    "    config_precision = personalization_df[personalization_df['metric'] == 'precision@10'].groupby('config')['precision@10'].max().reset_index()\n",
    "    config_ndcg = personalization_df[personalization_df['metric'] == 'ndcg@10'].groupby('config')['ndcg@10'].max().reset_index()\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    \n",
    "    x = np.arange(len(config_precision))\n",
    "    width = 0.35\n",
    "    \n",
    "    plt.bar(x - width/2, config_precision['precision@10'], width, label='Precision@10')\n",
    "    plt.bar(x + width/2, config_ndcg['ndcg@10'], width, label='NDCG@10')\n",
    "    \n",
    "    plt.xlabel('Configuration')\n",
    "    plt.ylabel('Performance Score')\n",
    "    plt.title('Best Performance by Configuration')\n",
    "    plt.xticks(x, config_precision['config'], rotation=45)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No personalization weight data available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze Embedding Weight Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "if embedding_df is not None:\n",
    "    # Display summary statistics\n",
    "    print(\"Summary statistics for embedding weights:\")\n",
    "    print(embedding_df.describe())\n",
    "    \n",
    "    # Find the best weights for precision\n",
    "    precision_df = embedding_df[embedding_df['metric'] == 'precision@10']\n",
    "    best_precision = precision_df.sort_values('precision@10', ascending=False).head(5)\n",
    "    print(\"\\nTop 5 weights for precision@10:\")\n",
    "    print(best_precision)\n",
    "    \n",
    "    # Find the best weights for NDCG\n",
    "    ndcg_df = embedding_df[embedding_df['metric'] == 'ndcg@10']\n",
    "    if not ndcg_df.empty:\n",
    "        best_ndcg = ndcg_df.sort_values('ndcg@10', ascending=False).head(5)\n",
    "        print(\"\\nTop 5 weights for ndcg@10:\")\n",
    "        print(best_ndcg)\n",
    "    \n",
    "    # Create a plot of summary_weight vs performance\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    \n",
    "    # Plot precision results\n",
    "    if not precision_df.empty:\n",
    "        plt.scatter(precision_df['summary_weight'], precision_df['precision@10'], \n",
    "                   label='Precision@10', alpha=0.7)\n",
    "    \n",
    "    # Plot NDCG results if available\n",
    "    if not ndcg_df.empty:\n",
    "        plt.scatter(ndcg_df['summary_weight'], ndcg_df['ndcg@10'], \n",
    "                   label='NDCG@10', alpha=0.7)\n",
    "    \n",
    "    plt.xlabel('Summary Weight')\n",
    "    plt.ylabel('Performance Score')\n",
    "    plt.title('Performance vs. Summary Weight')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No embedding weight data available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis of Non-Zero Performing Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Analyze all configurations that achieved non-zero performance\n",
    "if personalization_df is not None:\n",
    "    # Find all non-zero precision configurations\n",
    "    non_zero_precision = personalization_df[\n",
    "        (personalization_df['metric'] == 'precision@10') & \n",
    "        (personalization_df['precision@10'] > 0)\n",
    "    ].copy()\n",
    "    \n",
    "    print(f\"Found {len(non_zero_precision)} configurations with non-zero precision\")\n",
    "    \n",
    "    # Find all non-zero NDCG configurations\n",
    "    non_zero_ndcg = personalization_df[\n",
    "        (personalization_df['metric'] == 'ndcg@10') & \n",
    "        (personalization_df['ndcg@10'] > 0)\n",
    "    ].copy()\n",
    "    \n",
    "    print(f\"Found {len(non_zero_ndcg)} configurations with non-zero NDCG\")\n",
    "    \n",
    "    # Analyze patterns in non-zero configurations\n",
    "    if not non_zero_precision.empty:\n",
    "        print(\"\\nSummary of non-zero precision configurations:\")\n",
    "        \n",
    "        # Group by configuration type\n",
    "        config_counts = non_zero_precision['config'].value_counts()\n",
    "        print(f\"\\nConfiguration counts:\\n{config_counts}\")\n",
    "        \n",
    "        # Calculate weight statistics\n",
    "        print(\"\\nWeight statistics for non-zero precision configurations:\")\n",
    "        print(non_zero_precision[['expert_weight', 'historical_weight', 'categorical_weight']].describe())\n",
    "        \n",
    "        # Create histograms for each weight\n",
    "        fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "        \n",
    "        sns.histplot(non_zero_precision['expert_weight'], bins=10, kde=True, ax=axes[0])\n",
    "        axes[0].set_title('Expert Weight Distribution')\n",
    "        \n",
    "        sns.histplot(non_zero_precision['historical_weight'], bins=10, kde=True, ax=axes[1])\n",
    "        axes[1].set_title('Historical Weight Distribution')\n",
    "        \n",
    "        sns.histplot(non_zero_precision['categorical_weight'], bins=10, kde=True, ax=axes[2])\n",
    "        axes[2].set_title('Categorical Weight Distribution')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    # Detailed analysis of NDCG results\n",
    "    if not non_zero_ndcg.empty:\n",
    "        print(\"\\nSummary of non-zero NDCG configurations:\")\n",
    "        \n",
    "        # Group by configuration type\n",
    "        config_counts = non_zero_ndcg['config'].value_counts()\n",
    "        print(f\"\\nConfiguration counts:\\n{config_counts}\")\n",
    "        \n",
    "        # Calculate weight statistics\n",
    "        print(\"\\nWeight statistics for non-zero NDCG configurations:\")\n",
    "        print(non_zero_ndcg[['expert_weight', 'historical_weight', 'categorical_weight']].describe())\n",
    "        \n",
    "        # Plot NDCG values\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        sns.boxplot(x='config', y='ndcg@10', data=non_zero_ndcg)\n",
    "        plt.title('NDCG@10 Distribution by Configuration')\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "else:\n",
    "    print(\"No personalization data available for non-zero analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "\n",
    "Based on the analysis above, we can draw the following conclusions about the optimal weight configurations for the renewable energy client:\n",
    "\n",
    "1. **Best Overall Configuration**: [Your conclusion here based on the results]\n",
    "\n",
    "2. **Expert Profile Importance**: [Your conclusion here based on the results]\n",
    "\n",
    "3. **Historical vs. Categorical Weights**: [Your conclusion here based on the results]\n",
    "\n",
    "4. **Text vs. Categorical Similarity**: [Your conclusion here based on the results]\n",
    "\n",
    "5. **Embedding Weights (Summary vs. Keywords)**: [Your conclusion here based on the results]\n",
    "\n",
    "6. **Recommendations for Improvement**: [Your recommendations based on the analysis]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
