# EU Legal Document Recommender System

A sophisticated recommender system designed to match EU legal documents with user interests based on semantic similarity, document features, and user preferences.

## Architecture Overview

### Core Components

1. **Text Embedding (embeddings.py)**
   - Uses BERT (all-MiniLM-L6-v2) for semantic text understanding
   - Combines document summaries and keywords with weighted importance
   - Features:
     - Efficient batch processing
     - Embedding caching
     - GPU support when available

2. **Feature Processing (features.py)**
   - Handles categorical document attributes
   - Implements:
     - One-hot encoding for categorical features
     - Feature persistence and loading
     - Dynamic feature space adaptation

3. **Similarity Computation (similarity.py)**
   - Hybrid similarity calculation combining:
     - Text embedding similarity (70% weight)
     - Categorical feature similarity (30% weight)
   - Uses FAISS for efficient similarity search
   - Supports both exact and approximate nearest neighbor search

4. **Document Ranking (ranker.py)**
   - Combines all components for final recommendations
   - Provides configurable ranking parameters
   - Includes document and computation caching

### Input Features

1. **Text Features**
   - Document summaries (generated by our summarization pipeline)
   - Keywords (extracted using KeyBERT)
   - User interest descriptions

2. **Categorical Features**
   - Document Type (regulation, directive, decision)
   - Subject Matter
   - Legal Basis
   - Geographic Scope
   - Temporal Validity

## Installation

```bash
# Create and activate virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\\Scripts\\activate

# Install dependencies
pip install -r requirements.txt
```

## Usage

### Basic Usage

```python
from recommender.src.models.embeddings import BERTEmbedder
from recommender.src.models.features import FeatureProcessor
from recommender.src.models.similarity import SimilarityComputer
from recommender.src.models.ranker import DocumentRanker

# Initialize components
embedder = BERTEmbedder(model_name='all-MiniLM-L6-v2')
feature_processor = FeatureProcessor()
similarity_computer = SimilarityComputer(
    text_weight=0.7,
    categorical_weight=0.3
)

# Create ranker
ranker = DocumentRanker(
    embedder=embedder,
    feature_processor=feature_processor,
    similarity_computer=similarity_computer
)

# Process documents
documents = [
    {
        'id': 'doc1',
        'summary': 'Document summary text...',
        'keywords': ['keyword1', 'keyword2'],
        'features': {
            'type': 'regulation',
            'subject': 'environment',
            'scope': 'EU-wide'
        }
    },
    # ... more documents
]

ranker.process_documents(documents)

# Get recommendations
query_profile = {
    'interests': 'Environmental protection and climate change',
    'keywords': ['environment', 'climate', 'protection'],
    'features': {
        'type': 'regulation',
        'subject': 'environment',
        'scope': 'EU-wide'
    }
}

recommendations = ranker.rank_documents(
    query_profile,
    top_k=10,
    min_similarity=0.5
)
```

### Advanced Configuration

```python
# Enable GPU acceleration
embedder = BERTEmbedder(
    model_name='all-MiniLM-L6-v2',
    device='cuda'
)

# Configure similarity search
similarity_computer = SimilarityComputer(
    text_weight=0.7,
    categorical_weight=0.3,
    use_faiss=True  # Enable FAISS for faster search
)

# Enable caching
ranker = DocumentRanker(
    embedder=embedder,
    feature_processor=feature_processor,
    similarity_computer=similarity_computer,
    cache_dir='./cache'
)
```

## Performance Optimization

1. **Batch Processing**
   - Documents are processed in batches
   - Configurable batch size for memory management
   - Parallel processing where applicable

2. **Caching System**
   - Embeddings cache
   - Feature encoding cache
   - FAISS index persistence

3. **GPU Acceleration**
   - BERT model can run on GPU
   - FAISS GPU support available
   - Batch size optimization for GPU memory

## Evaluation Metrics

1. **Relevance Metrics**
   - Mean Reciprocal Rank (MRR)
   - Normalized Discounted Cumulative Gain (NDCG)
   - Precision@k
   - Recall@k

2. **Performance Metrics**
   - Processing time per document
   - Query response time
   - Memory usage
   - GPU utilization (if applicable)

## Future Enhancements

1. **Model Improvements**
   - Fine-tune BERT model on legal documents
   - Implement attention mechanisms for keyword weighting
   - Add support for multi-lingual embeddings

2. **Feature Engineering**
   - Add temporal relevance scoring
   - Implement citation-based features
   - Add document complexity metrics

3. **System Optimization**
   - Implement distributed processing
   - Add real-time update capability
   - Optimize memory usage for large document sets

4. **User Interface**
   - Web-based interface for queries
   - Result visualization
   - User feedback integration

## Contributing

1. Fork the repository
2. Create your feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit your changes (`git commit -m 'Add some AmazingFeature'`)
4. Push to the branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request

## License

This project is licensed under the MIT License - see the LICENSE file for details.

## Acknowledgments

- Built using the Sentence-Transformers library
- FAISS library for efficient similarity search
- scikit-learn for feature processing
